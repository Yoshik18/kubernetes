# Logging and Monitoring 

## Container Logging

### What is Container Logging?
**Container Logging** is the process of collecting, storing, and accessing application logs generated by containers running in pods.

### Docker vs Kubernetes Logging

#### Docker Logging
```bash
# Run container and view logs directly
docker run kodekloud/event-simulator

# Run in detached mode and view logs
docker run -d kodekloud/event-simulator
docker logs -f 
```

#### Kubernetes Logging
```bash
# Create pod and view logs
kubectl create -f event-simulator.yaml
kubectl logs -f event-simulator-pod
```

### Log Access Methods

#### Single Container Pod
```bash
# View logs from single container pod
kubectl logs 

# Follow logs in real-time
kubectl logs -f 

# View previous container logs (after restart)
kubectl logs  --previous
```

#### Multi-Container Pod
```bash
# Specify container name for multi-container pods
kubectl logs -f  

# Example with multi-container pod
kubectl logs -f event-simulator-pod event-simulator
```

### Pod Definition for Logging
```yaml
# Single container pod
apiVersion: v1
kind: Pod
metadata:
  name: event-simulator-pod
spec:
  containers:
  - name: event-simulator
    image: kodekloud/event-simulator
```

```yaml
# Multi-container pod
apiVersion: v1
kind: Pod
metadata:
  name: event-simulator-pod
spec:
  containers:
  - name: event-simulator
    image: kodekloud/event-simulator
  - name: image-processor
    image: some-image-processor
```

### Log Storage Locations
- **Container Runtime**: Docker stores logs in `/var/lib/docker/containers/`
- **Kubelet**: Manages log rotation and cleanup
- **Node-level**: Logs accessible via kubectl from any cluster node

### Log Limitations
- **Ephemeral**: Logs are lost when pods are deleted
- **No centralized storage**: Logs stored locally on nodes
- **Limited retention**: Subject to log rotation policies
- **No aggregation**: No built-in cross-pod log correlation

## Kubernetes Monitoring

### What is Monitoring in Kubernetes?
**Monitoring** is the continuous observation of cluster and application performance through metrics collection, storage, and analysis.

### Key Metrics to Monitor

#### Node-Level Metrics
- **CPU Usage**: Processor utilization across nodes
- **Memory Usage**: RAM consumption and availability
- **Disk Usage**: Storage utilization and I/O performance
- **Network**: Traffic, latency, and packet loss

#### Pod-Level Metrics
- **Resource Consumption**: CPU, memory usage per pod
- **Restart Count**: Pod failure and restart frequency
- **Health Status**: Pod readiness and liveness states

#### Cluster-Level Metrics
- **API Server Performance**: Request latency and throughput
- **Scheduler Performance**: Pod placement efficiency
- **Controller Performance**: Reconciliation loop metrics

### Monitoring Solutions

#### Built-in Solutions
- **Metrics Server**: Lightweight, resource metrics collection
- **cAdvisor**: Container-level resource usage statistics

#### Third-Party Solutions
- **Prometheus**: Open-source monitoring and alerting
- **Elastic Stack**: Log aggregation and analysis
- **Datadog**: Commercial monitoring platform
- **Dynatrace**: Application performance monitoring

## Metrics Server

### What is Metrics Server?
**Metrics Server** is a cluster-wide aggregator of resource usage data that provides CPU and memory metrics for nodes and pods.

### Metrics Server vs Heapster

| Feature | Heapster (Deprecated) | Metrics Server |
|---------|----------------------|----------------|
| **Status** | Deprecated in K8s 1.11 | Current standard |
| **Storage** | Persistent storage | In-memory only |
| **Scope** | Full monitoring solution | Resource metrics only |
| **Performance** | Heavier resource usage | Lightweight |
| **API** | Custom API | Standard Metrics API |

### Metrics Server Architecture

#### Components
- **Metrics Server Pod**: Collects and aggregates metrics
- **Kubelet Integration**: Pulls metrics from kubelet on each node
- **cAdvisor**: Provides container-level metrics to kubelet
- **API Server**: Exposes metrics via Kubernetes API

#### Data Flow
```
cAdvisor → Kubelet → Metrics Server → Kubernetes API → kubectl top
```

### Metrics Server Installation

#### Minikube
```bash
# Enable metrics-server addon
minikube addons enable metrics-server
```

#### Manual Installation
```bash
# Clone metrics-server repository
git clone https://github.com/kubernetes-incubator/metrics-server.git

# Deploy metrics-server
kubectl create -f deploy/1.8+/
```

#### Installation Output
```bash
clusterrolebinding "metrics-server:system:auth-delegator" created
rolebinding "metrics-server-auth-reader" created
apiservice "v1beta1.metrics.k8s.io" created
serviceaccount "metrics-server" created
deployment "metrics-server" created
service "metrics-server" created
clusterrole "system:metrics-server" created
clusterrolebinding "system:metrics-server" created
```

### Using Metrics Server

#### View Node Metrics
```bash
kubectl top node
```
```
NAME          CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
kubemaster    166m         8%     1337Mi          70%
kubenode1     36m          1%     1046Mi          55%
kubenode2     39m          1%     1048Mi          55%
```

#### View Pod Metrics
```bash
kubectl top pod
```
```
NAME    CPU(cores)   MEMORY(bytes)
nginx   5m          10Mi
redis   2m          15Mi
```

#### Namespace-Specific Metrics
```bash
# View pods in specific namespace
kubectl top pod -n kube-system

# View all namespaces
kubectl top pod --all-namespaces
```

### Metrics Server Data Storage
- **In-Memory Only**: No persistent storage of historical data
- **Real-Time**: Provides current resource usage only
- **Aggregation Period**: Typically 15-60 second intervals
- **Retention**: Limited to current metrics only

## Advanced Monitoring Concepts

### Resource Requests vs Usage
- **Requests**: Resources guaranteed by scheduler
- **Usage**: Actual resources consumed by container
- **Monitoring Value**: Usage vs requests comparison shows over/under-provisioning

### Horizontal Pod Autoscaler (HPA) Integration
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

### Custom Metrics
- **Application Metrics**: Business-specific measurements
- **Custom Resource Metrics**: GPU, network bandwidth
- **External Metrics**: Cloud provider metrics, external services

## Logging Best Practices

### Application Logging
- **Structured Logging**: Use JSON format for easier parsing
- **Log Levels**: Implement DEBUG, INFO, WARN, ERROR levels
- **Contextual Information**: Include request IDs, user IDs, timestamps

### Container Logging Standards
- **Stdout/Stderr**: Write logs to standard output streams
- **Avoid File Logging**: Don't write logs to container filesystem
- **Single Process**: One main process per container for log clarity

### Log Management
```bash
# View logs with timestamps
kubectl logs  --timestamps

# Limit log output
kubectl logs  --tail=100

# Filter logs by time
kubectl logs  --since=1h
```

## Monitoring Best Practices

### Metrics Collection
- **Resource Limits**: Set appropriate CPU/memory limits
- **Health Checks**: Implement liveness and readiness probes
- **Service Monitoring**: Monitor service endpoints and response times

### Alerting Strategy
- **Threshold-Based**: CPU > 80%, Memory > 90%
- **Trend-Based**: Resource usage growing over time
- **Service-Level**: Application-specific metrics and SLAs

### Dashboard Design
- **Node Overview**: Cluster-wide resource utilization
- **Application Metrics**: Service-specific performance
- **Infrastructure Health**: Node status, pod distribution

## Troubleshooting Common Issues

### Metrics Server Issues
```bash
# Check metrics-server status
kubectl get pods -n kube-system | grep metrics-server

# View metrics-server logs
kubectl logs -n kube-system deployment/metrics-server

# Verify metrics API
kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes
```

### Logging Issues
```bash
# Pod not generating logs
kubectl describe pod 

# Container exit codes
kubectl get pods -o wide

# Previous container logs after restart
kubectl logs  --previous
```

### Performance Troubleshooting
```bash
# High CPU usage investigation
kubectl top pods --sort-by=cpu

# Memory pressure analysis
kubectl top pods --sort-by=memory

# Node resource availability
kubectl describe node 
```

## Version Compatibility Notes

### Kubernetes Version Support
- **Metrics Server**: Supported in K8s 1.8+
- **Heapster**: Deprecated since K8s 1.11
- **Play-with-K8s**: Uses K8s 1.8, may require Heapster

### Migration Considerations
- **Legacy Clusters**: May still use Heapster
- **Upgrade Path**: Migrate from Heapster to Metrics Server
- **API Changes**: Update monitoring tools to use Metrics API

## Key Commands Summary

### Logging Commands
```bash
# Basic log viewing
kubectl logs 
kubectl logs -f   # Follow logs
kubectl logs  -c   # Multi-container

# Advanced log options
kubectl logs  --timestamps
kubectl logs  --tail=50
kubectl logs  --since=2h
kubectl logs  --previous  # Previous container
```

### Monitoring Commands
```bash
# Resource usage
kubectl top nodes
kubectl top pods
kubectl top pods --all-namespaces
kubectl top pods --sort-by=cpu

# Metrics server
kubectl get pods -n kube-system | grep metrics
kubectl get apiservice | grep metrics
```

### Troubleshooting Commands
```bash
# Pod investigation
kubectl describe pod 
kubectl get events --sort-by=.metadata.creationTimestamp

# Node investigation
kubectl describe node 
kubectl get nodes -o wide
```